{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "import json\r\n",
        "\r\n",
        "# Load data into a string\r\n",
        "# Data for an entire OLTP database is in one string so I do not load it into a dataframe\r\n",
        "\r\n",
        "raw_json = spark.read.text('abfss://files@chinook2608.dfs.core.windows.net/data/ChinookData.json').collect()\r\n",
        "json_string = \"\\n\".join([row[0] for row in raw_json])\r\n",
        "data = json.loads(json_string)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "PySparkPool",
              "statement_id": 2,
              "statement_ids": [
                2
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "5",
              "normalized_state": "finished",
              "queued_time": "2025-02-07T12:37:18.2452828Z",
              "session_start_time": "2025-02-07T12:37:18.2804892Z",
              "execution_start_time": "2025-02-07T12:40:47.6025503Z",
              "execution_finish_time": "2025-02-07T12:41:02.51734Z",
              "parent_msg_id": "a6493f12-6fed-4631-b008-bd05a1063e10"
            },
            "text/plain": "StatementMeta(PySparkPool, 5, 2, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\r\n",
        "for key in data.keys():\r\n",
        "    print(key)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "PySparkPool",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "5",
              "normalized_state": "finished",
              "queued_time": "2025-02-07T12:37:44.0729623Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-07T12:41:02.6442963Z",
              "execution_finish_time": "2025-02-07T12:41:02.8012519Z",
              "parent_msg_id": "9a536822-460d-4a5f-82bb-0c6516027b13"
            },
            "text/plain": "StatementMeta(PySparkPool, 5, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genre\nMediaType\nArtist\nAlbum\nTrack\nEmployee\nCustomer\nInvoice\nInvoiceLine\nPlaylist\nPlaylistTrack\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe for every OLTP table\r\n",
        "\r\n",
        "genre_df = spark.createDataFrame(data['Genre'])\r\n",
        "mediatype_df = spark.createDataFrame(data['MediaType'])\r\n",
        "artist_df = spark.createDataFrame(data['Artist'])\r\n",
        "album_df = spark.createDataFrame(data['Album'])\r\n",
        "track_df = spark.createDataFrame(data['Track'])\r\n",
        "employee_df = spark.createDataFrame(data['Employee'])\r\n",
        "customer_df = spark.createDataFrame(data['Customer'])\r\n",
        "invoice_df = spark.createDataFrame(data['Invoice'])\r\n",
        "invoiceline_df = spark.createDataFrame(data['InvoiceLine'])\r\n",
        "playlist_df = spark.createDataFrame(data['Playlist'])\r\n",
        "playlisttrack_df = spark.createDataFrame(data['PlaylistTrack'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "PySparkPool",
              "statement_id": 4,
              "statement_ids": [
                4
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "5",
              "normalized_state": "finished",
              "queued_time": "2025-02-07T12:38:28.0196958Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-07T12:41:02.9333473Z",
              "execution_finish_time": "2025-02-07T12:41:04.7549129Z",
              "parent_msg_id": "6b1b8efe-eb13-47f4-bcd8-de523cef10c4"
            },
            "text/plain": "StatementMeta(PySparkPool, 5, 4, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(genre_df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "PySparkPool",
              "statement_id": 5,
              "statement_ids": [
                5
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "5",
              "normalized_state": "finished",
              "queued_time": "2025-02-07T12:38:29.7736506Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-07T12:41:04.8877252Z",
              "execution_finish_time": "2025-02-07T12:41:27.7097059Z",
              "parent_msg_id": "5311adc3-1042-4ef0-9994-f3a394f281cc"
            },
            "text/plain": "StatementMeta(PySparkPool, 5, 5, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.widget-view+json": {
              "widget_id": "578ebad2-51dd-45eb-867a-bafe8ae8cd43",
              "widget_type": "Synapse.DataFrame"
            },
            "text/plain": "SynapseWidget(Synapse.DataFrame, 578ebad2-51dd-45eb-867a-bafe8ae8cd43)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataframes as parquet files\r\n",
        "\r\n",
        "genre_df.write.mode(\"overwrite\").parquet('/dataframes/genre.parquet')\r\n",
        "mediatype_df.write.mode(\"overwrite\").parquet('/dataframes/mediatype.parquet')\r\n",
        "artist_df.write.mode(\"overwrite\").parquet('/dataframes/artist.parquet')\r\n",
        "album_df.write.mode(\"overwrite\").parquet('/dataframes/album.parquet')\r\n",
        "track_df.write.mode(\"overwrite\").parquet('/dataframes/track.parquet')\r\n",
        "employee_df.write.mode(\"overwrite\").parquet('/dataframes/employee.parquet')\r\n",
        "customer_df.write.mode(\"overwrite\").parquet('/dataframes/customer.parquet')\r\n",
        "invoice_df.write.mode(\"overwrite\").parquet('/dataframes/invoice.parquet')\r\n",
        "invoiceline_df.write.mode(\"overwrite\").parquet('/dataframes/invoiceline.parquet')\r\n",
        "playlist_df.write.mode(\"overwrite\").parquet('/dataframes/playlist.parquet')\r\n",
        "playlisttrack_df.write.mode(\"overwrite\").parquet('/dataframes/playlisttrack.parquet')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "PySparkPool",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "5",
              "normalized_state": "finished",
              "queued_time": "2025-02-07T12:38:30.9786368Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-07T12:41:27.8526925Z",
              "execution_finish_time": "2025-02-07T12:41:50.1061283Z",
              "parent_msg_id": "86bde06a-ff24-4dd6-82ae-20473ec5ef22"
            },
            "text/plain": "StatementMeta(PySparkPool, 5, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataframes in delta format\r\n",
        "\r\n",
        "genre_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/genre')\r\n",
        "mediatype_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/mediatype')\r\n",
        "artist_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/artist')\r\n",
        "album_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/album')\r\n",
        "track_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/track')\r\n",
        "employee_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/employee')\r\n",
        "customer_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/customer')\r\n",
        "invoice_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/invoice')\r\n",
        "invoiceline_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/invoiceline')\r\n",
        "playlist_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/playlist')\r\n",
        "playlisttrack_df.write.format(\"delta\").mode(\"overwrite\").save('/delta/playlisttrack')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "PySparkPool",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "5",
              "normalized_state": "finished",
              "queued_time": "2025-02-07T12:38:32.6588608Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-07T12:41:50.2465201Z",
              "execution_finish_time": "2025-02-07T12:42:54.2496343Z",
              "parent_msg_id": "9c250263-b168-4dda-a730-6d36d623a94c"
            },
            "text/plain": "StatementMeta(PySparkPool, 5, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {
        "578ebad2-51dd-45eb-867a-bafe8ae8cd43": {
          "type": "Synapse.DataFrame",
          "sync_state": {
            "table": {
              "rows": [
                {
                  "0": "1",
                  "1": "Rock"
                },
                {
                  "0": "2",
                  "1": "Jazz"
                },
                {
                  "0": "3",
                  "1": "Metal"
                },
                {
                  "0": "4",
                  "1": "Alternative & Punk"
                },
                {
                  "0": "5",
                  "1": "Rock And Roll"
                },
                {
                  "0": "6",
                  "1": "Blues"
                },
                {
                  "0": "7",
                  "1": "Latin"
                },
                {
                  "0": "8",
                  "1": "Reggae"
                },
                {
                  "0": "9",
                  "1": "Pop"
                },
                {
                  "0": "10",
                  "1": "Soundtrack"
                },
                {
                  "0": "11",
                  "1": "Bossa Nova"
                },
                {
                  "0": "12",
                  "1": "Easy Listening"
                },
                {
                  "0": "13",
                  "1": "Heavy Metal"
                },
                {
                  "0": "14",
                  "1": "R&B/Soul"
                },
                {
                  "0": "15",
                  "1": "Electronica/Dance"
                },
                {
                  "0": "16",
                  "1": "World"
                },
                {
                  "0": "17",
                  "1": "Hip Hop/Rap"
                },
                {
                  "0": "18",
                  "1": "Science Fiction"
                },
                {
                  "0": "19",
                  "1": "TV Shows"
                },
                {
                  "0": "20",
                  "1": "Sci Fi & Fantasy"
                },
                {
                  "0": "21",
                  "1": "Drama"
                },
                {
                  "0": "22",
                  "1": "Comedy"
                },
                {
                  "0": "23",
                  "1": "Alternative"
                },
                {
                  "0": "24",
                  "1": "Classical"
                },
                {
                  "0": "25",
                  "1": "Opera"
                }
              ],
              "schema": [
                {
                  "key": "0",
                  "name": "GenreId",
                  "type": "bigint"
                },
                {
                  "key": "1",
                  "name": "Name",
                  "type": "string"
                }
              ],
              "truncated": false
            },
            "isSummary": false,
            "language": "scala",
            "wranglerEntryContext": {
              "candidateVariableNames": [
                "genre_df"
              ],
              "dataframeType": "pyspark"
            }
          },
          "persist_state": {
            "view": {
              "type": "details",
              "tableOptions": {},
              "chartOptions": {
                "chartType": "bar",
                "aggregationType": "sum",
                "categoryFieldKeys": [
                  "1"
                ],
                "seriesFieldKeys": [
                  "0"
                ],
                "isStacked": false
              }
            }
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}